{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car price prediction using Apache spark and python wit AWS S3\n",
    "by moses kiboma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Definition\n",
    "#### How to determine the *price* of a used car?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findspark\n",
    "\n",
    "Use `findspark` to be able to find and import **Pyspark** module, while correctly setting environmental variables and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import findspark\n",
    "try:\n",
    "    findspark.init('/opt/spark')\n",
    "except:\n",
    "    print (\"Error:\", ''.join(traceback.format_stack()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check paths before Executing PySpark Session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH: /home/moses/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\n",
      "\n",
      "SPARK_HOME: /opt/spark\n",
      "PYSPARK_PYTHON: /bin/python3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print(\"PATH: %s\\n\" % os.environ['PATH'])\n",
    "print(\"SPARK_HOME: %s\" % os.environ['SPARK_HOME'])\n",
    "print(\"PYSPARK_PYTHON: %s\" % os.environ['PYSPARK_PYTHON'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "from pyspark.sql.functions import *\n",
    "from functools import reduce\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.4.1\n",
      "numpy: 1.22.2\n",
      "matplotlib: 3.5.1\n",
      "seaborn: 0.11.2\n",
      "Python: 3.8.10 (default, Mar 15 2022, 12:22:08) \n",
      "[GCC 9.4.0]\n"
     ]
    }
   ],
   "source": [
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('seaborn: {}'.format(sns.__version__))\n",
    "print('Python: {}'.format(sys.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating SparkSession\n",
    "Get package to handle AWS to access S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYSPARK_SUBMIT_ARGS=--packages=org.apache.hadoop:hadoop-aws:2.7.3 pyspark-shell\n"
     ]
    }
   ],
   "source": [
    "%set_env PYSPARK_SUBMIT_ARGS=--packages=org.apache.hadoop:hadoop-aws:2.7.3 pyspark-shell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Spark Session, hosted across all local nodes on a **Standalone Cluster**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/06 21:28:06 WARN Utils: Your hostname, kiboma resolves to a loopback address: 127.0.1.1; using 192.168.0.103 instead (on interface wlo1)\n",
      "22/04/06 21:28:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/moses/.ivy2/cache\n",
      "The jars for the packages stored in: /home/moses/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-36b5e920-74c0-4982-a4a1-42659c5aed7d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;2.7.3 in central\n",
      "\tfound org.apache.hadoop#hadoop-common;2.7.3 in central\n",
      "\tfound org.apache.hadoop#hadoop-annotations;2.7.3 in central\n",
      "\tfound com.google.guava#guava;11.0.2 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound commons-cli#commons-cli;1.2 in central\n",
      "\tfound org.apache.commons#commons-math3;3.1.1 in central\n",
      "\tfound xmlenc#xmlenc;0.52 in central\n",
      "\tfound commons-httpclient#commons-httpclient;3.1 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.4 in central\n",
      "\tfound commons-io#commons-io;2.4 in central\n",
      "\tfound commons-net#commons-net;3.1 in central\n",
      "\tfound commons-collections#commons-collections;3.2.2 in central\n",
      "\tfound javax.servlet#servlet-api;2.5 in central\n",
      "\tfound org.mortbay.jetty#jetty;6.1.26 in central\n",
      "\tfound org.mortbay.jetty#jetty-util;6.1.26 in central\n",
      "\tfound com.sun.jersey#jersey-core;1.9 in central\n",
      "\tfound com.sun.jersey#jersey-json;1.9 in central\n",
      "\tfound org.codehaus.jettison#jettison;1.1 in central\n",
      "\tfound com.sun.xml.bind#jaxb-impl;2.2.3-1 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.2.2 in central\n",
      "\tfound javax.xml.stream#stax-api;1.0-2 in central\n",
      "\tfound javax.activation#activation;1.1 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-jaxrs;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-xc;1.9.13 in central\n",
      "\tfound com.sun.jersey#jersey-server;1.9 in central\n",
      "\tfound asm#asm;3.2 in central\n",
      "\tfound log4j#log4j;1.2.17 in central\n",
      "\tfound net.java.dev.jets3t#jets3t;0.9.0 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.2.5 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.2.5 in central\n",
      "\tfound com.jamesmurty.utils#java-xmlbuilder;0.4 in central\n",
      "\tfound commons-lang#commons-lang;2.6 in central\n",
      "\tfound commons-configuration#commons-configuration;1.6 in central\n",
      "\tfound commons-digester#commons-digester;1.8 in central\n",
      "\tfound commons-beanutils#commons-beanutils;1.7.0 in central\n",
      "\tfound commons-beanutils#commons-beanutils-core;1.8.0 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.10 in central\n",
      "\tfound org.apache.avro#avro;1.7.4 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.3 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.0.4.1 in central\n",
      "\tfound org.apache.commons#commons-compress;1.4.1 in central\n",
      "\tfound org.tukaani#xz;1.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java;2.5.0 in central\n",
      "\tfound com.google.code.gson#gson;2.2.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-auth;2.7.3 in central\n",
      "\tfound org.apache.directory.server#apacheds-kerberos-codec;2.0.0-M15 in central\n",
      "\tfound org.apache.directory.server#apacheds-i18n;2.0.0-M15 in central\n",
      "\tfound org.apache.directory.api#api-asn1-api;1.0.0-M20 in central\n",
      "\tfound org.apache.directory.api#api-util;1.0.0-M20 in central\n",
      "\tfound org.apache.zookeeper#zookeeper;3.4.6 in central\n",
      "\tfound org.slf4j#slf4j-log4j12;1.7.10 in central\n",
      "\tfound io.netty#netty;3.6.2.Final in central\n",
      "\tfound org.apache.curator#curator-framework;2.7.1 in central\n",
      "\tfound org.apache.curator#curator-client;2.7.1 in central\n",
      "\tfound com.jcraft#jsch;0.1.42 in central\n",
      "\tfound org.apache.curator#curator-recipes;2.7.1 in central\n",
      "\tfound org.apache.htrace#htrace-core;3.1.0-incubating in central\n",
      "\tfound javax.servlet.jsp#jsp-api;2.1 in central\n",
      "\tfound jline#jline;0.9.94 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.2.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.2.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.2.3 in central\n",
      "\tfound com.amazonaws#aws-java-sdk;1.7.4 in central\n",
      "You probably access the destination server through a proxy server that is not well configured.\n",
      "You probably access the destination server through a proxy server that is not well configured.\n",
      "You probably access the destination server through a proxy server that is not well configured.\n",
      "You probably access the destination server through a proxy server that is not well configured.\n",
      "You probably access the destination server through a proxy server that is not well configured.\n",
      "You probably access the destination server through a proxy server that is not well configured.\n",
      ":: resolution report :: resolve 5189ms :: artifacts dl 225ms\n",
      "\t:: modules in use:\n",
      "\tasm#asm;3.2 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk;1.7.4 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.2.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.2.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.2.3 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.2.4 from central in [default]\n",
      "\tcom.google.guava#guava;11.0.2 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 from central in [default]\n",
      "\tcom.jamesmurty.utils#java-xmlbuilder;0.4 from central in [default]\n",
      "\tcom.jcraft#jsch;0.1.42 from central in [default]\n",
      "\tcom.sun.jersey#jersey-core;1.9 from central in [default]\n",
      "\tcom.sun.jersey#jersey-json;1.9 from central in [default]\n",
      "\tcom.sun.jersey#jersey-server;1.9 from central in [default]\n",
      "\tcom.sun.xml.bind#jaxb-impl;2.2.3-1 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.3 from central in [default]\n",
      "\tcommons-beanutils#commons-beanutils;1.7.0 from central in [default]\n",
      "\tcommons-beanutils#commons-beanutils-core;1.8.0 from central in [default]\n",
      "\tcommons-cli#commons-cli;1.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.4 from central in [default]\n",
      "\tcommons-collections#commons-collections;3.2.2 from central in [default]\n",
      "\tcommons-configuration#commons-configuration;1.6 from central in [default]\n",
      "\tcommons-digester#commons-digester;1.8 from central in [default]\n",
      "\tcommons-httpclient#commons-httpclient;3.1 from central in [default]\n",
      "\tcommons-io#commons-io;2.4 from central in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tcommons-net#commons-net;3.1 from central in [default]\n",
      "\tio.netty#netty;3.6.2.Final from central in [default]\n",
      "\tjavax.activation#activation;1.1 from central in [default]\n",
      "\tjavax.servlet#servlet-api;2.5 from central in [default]\n",
      "\tjavax.servlet.jsp#jsp-api;2.1 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.2.2 from central in [default]\n",
      "\tjavax.xml.stream#stax-api;1.0-2 from central in [default]\n",
      "\tjline#jline;0.9.94 from central in [default]\n",
      "\tlog4j#log4j;1.2.17 from central in [default]\n",
      "\tnet.java.dev.jets3t#jets3t;0.9.0 from central in [default]\n",
      "\torg.apache.avro#avro;1.7.4 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.4.1 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.1.1 from central in [default]\n",
      "\torg.apache.curator#curator-client;2.7.1 from central in [default]\n",
      "\torg.apache.curator#curator-framework;2.7.1 from central in [default]\n",
      "\torg.apache.curator#curator-recipes;2.7.1 from central in [default]\n",
      "\torg.apache.directory.api#api-asn1-api;1.0.0-M20 from central in [default]\n",
      "\torg.apache.directory.api#api-util;1.0.0-M20 from central in [default]\n",
      "\torg.apache.directory.server#apacheds-i18n;2.0.0-M15 from central in [default]\n",
      "\torg.apache.directory.server#apacheds-kerberos-codec;2.0.0-M15 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-annotations;2.7.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-auth;2.7.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;2.7.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-common;2.7.3 from central in [default]\n",
      "\torg.apache.htrace#htrace-core;3.1.0-incubating from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.2.5 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.2.5 from central in [default]\n",
      "\torg.apache.zookeeper#zookeeper;3.4.6 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-jaxrs;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-xc;1.9.13 from central in [default]\n",
      "\torg.codehaus.jettison#jettison;1.1 from central in [default]\n",
      "\torg.mortbay.jetty#jetty;6.1.26 from central in [default]\n",
      "\torg.mortbay.jetty#jetty-util;6.1.26 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.10 from central in [default]\n",
      "\torg.slf4j#slf4j-log4j12;1.7.10 from central in [default]\n",
      "\torg.tukaani#xz;1.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.0.4.1 from central in [default]\n",
      "\txmlenc#xmlenc;0.52 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   68  |   0   |   0   |   0   ||   67  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      "\n",
      ":: problems summary ::\n",
      ":::: WARNINGS\n",
      "\tHost repo1.maven.org not found. url=https://repo1.maven.org/maven2/joda-time/joda-time/maven-metadata.xml\n",
      "\n",
      "\tHost repo1.maven.org not found. url=https://repo1.maven.org/maven2/joda-time/joda-time/\n",
      "\n",
      "\tHost repo1.maven.org not found. url=https://repo1.maven.org/maven2/joda-time/joda-time/\n",
      "\n",
      "\tHost repos.spark-packages.org not found. url=https://repos.spark-packages.org/joda-time/joda-time/maven-metadata.xml\n",
      "\n",
      "\tHost repos.spark-packages.org not found. url=https://repos.spark-packages.org/joda-time/joda-time/\n",
      "\n",
      "\tHost repos.spark-packages.org not found. url=https://repos.spark-packages.org/joda-time/joda-time/\n",
      "\n",
      "\t\tmodule not found: joda-time#joda-time;[2.2,)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/moses/.m2/repository/joda-time/joda-time/[revision]/joda-time-[revision].pom\n",
      "\n",
      "\t  -- artifact joda-time#joda-time;[2.2,)!joda-time.jar:\n",
      "\n",
      "\t  file:/home/moses/.m2/repository/joda-time/joda-time/[revision]/joda-time-[revision].jar\n",
      "\n",
      "\t==== local-ivy-cache: tried\n",
      "\n",
      "\t  /home/moses/.ivy2/local/joda-time/joda-time/[revision]/ivys/ivy.xml\n",
      "\n",
      "\t  -- artifact joda-time#joda-time;[2.2,)!joda-time.jar:\n",
      "\n",
      "\t  /home/moses/.ivy2/local/joda-time/joda-time/[revision]/jars/joda-time.jar\n",
      "\n",
      "\t==== central: tried\n",
      "\n",
      "\t  https://repo1.maven.org/maven2/joda-time/joda-time/[revision]/joda-time-[revision].pom\n",
      "\n",
      "\t  -- artifact joda-time#joda-time;[2.2,)!joda-time.jar:\n",
      "\n",
      "\t  https://repo1.maven.org/maven2/joda-time/joda-time/[revision]/joda-time-[revision].jar\n",
      "\n",
      "\t==== spark-packages: tried\n",
      "\n",
      "\t  https://repos.spark-packages.org/joda-time/joda-time/[revision]/joda-time-[revision].pom\n",
      "\n",
      "\t  -- artifact joda-time#joda-time;[2.2,)!joda-time.jar:\n",
      "\n",
      "\t  https://repos.spark-packages.org/joda-time/joda-time/[revision]/joda-time-[revision].jar\n",
      "\n",
      "\t\t::::::::::::::::::::::::::::::::::::::::::::::\n",
      "\n",
      "\t\t::          UNRESOLVED DEPENDENCIES         ::\n",
      "\n",
      "\t\t::::::::::::::::::::::::::::::::::::::::::::::\n",
      "\n",
      "\t\t:: joda-time#joda-time;[2.2,): not found\n",
      "\n",
      "\t\t::::::::::::::::::::::::::::::::::::::::::::::\n",
      "\n",
      "\n",
      "\n",
      ":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\n",
      "Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: joda-time#joda-time;[2.2,): not found]\n",
      "\tat org.apache.spark.deploy.SparkSubmitUtils$.resolveMavenCoordinates(SparkSubmit.scala:1447)\n",
      "\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:185)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:308)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:898)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1043)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1052)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaster\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocal[*]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPySpark Craigslist\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.some.config.option\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msome-value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m sc \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msparkContext\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/session.py:228\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m         sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m     sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc)\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/context.py:392\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 392\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/context.py:144\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 144\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\u001b[1;32m    147\u001b[0m                   conf, jsc, profiler_cls)\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/context.py:339\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[0;32m--> 339\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/java_gateway.py:108\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJava gateway process exited before sending its port number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(conn_info_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m info:\n\u001b[1;32m    111\u001b[0m     gateway_port \u001b[38;5;241m=\u001b[39m read_int(info)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"PySpark Craigslist\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure Hadoop connection for S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoopConf=spark.sparkContext._jsc.hadoopConfiguration()\n",
    "hadoopConf.set(\"fs.s3a.access.key\", \"AKIAQQADETG4J56SFQIV\")\n",
    "hadoopConf.set(\"fs.s3a.secret.key\", \"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitoring Spark instrumentation through the WebUI available through `localhost:4040/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Dataset\n",
    "\n",
    "https://www.truecar.com/used-cars-for-sale/listings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carsdata = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"cars.csv\")\n",
    "type(carsdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is available as a local *dataframe* on the Spark cluster, let's validate the dataframe by look at the schema, size, samples and statistics of our working data - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- region_url: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- manufacturer: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- cylinders: string (nullable = true)\n",
      " |-- fuel: string (nullable = true)\n",
      " |-- odometer: string (nullable = true)\n",
      " |-- title_status: string (nullable = true)\n",
      " |-- transmission: string (nullable = true)\n",
      " |-- VIN: string (nullable = true)\n",
      " |-- drive: string (nullable = true)\n",
      " |-- size: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- paint_color: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- lat: string (nullable = true)\n",
      " |-- long: string (nullable = true)\n",
      " |-- posting_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "carsdata.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensions of Raw Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441802 26\n"
     ]
    }
   ],
   "source": [
    "print(carsdata.count(),len(carsdata.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting random sample to see what kind of data populates each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/05 15:20:53 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>region</th>\n",
       "      <th>region_url</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>...</th>\n",
       "      <th>size</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>image_url</th>\n",
       "      <th>description</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>posting_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7309153014</td>\n",
       "      <td>https://omaha.craigslist.org/ctd/d/council-blu...</td>\n",
       "      <td>omaha / council bluffs</td>\n",
       "      <td>https://omaha.craigslist.org</td>\n",
       "      <td>7495</td>\n",
       "      <td>2010</td>\n",
       "      <td>honda</td>\n",
       "      <td>civic sedan</td>\n",
       "      <td>None</td>\n",
       "      <td>4 cylinders</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>sedan</td>\n",
       "      <td>black</td>\n",
       "      <td>https://images.craigslist.org/00o0o_fspI4HDewO...</td>\n",
       "      <td>2010 *Honda* *Civic Sedan* 4dr Automatic LX-S ...</td>\n",
       "      <td>None</td>\n",
       "      <td>ia</td>\n",
       "      <td>41.229172</td>\n",
       "      <td>-95.852118</td>\n",
       "      <td>2021-04-19T07:21:13-0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7314502745</td>\n",
       "      <td>https://nashville.craigslist.org/ctd/d/white-h...</td>\n",
       "      <td>nashville</td>\n",
       "      <td>https://nashville.craigslist.org</td>\n",
       "      <td>32900</td>\n",
       "      <td>2019</td>\n",
       "      <td>ford</td>\n",
       "      <td>transit</td>\n",
       "      <td>like new</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>...</td>\n",
       "      <td>full-size</td>\n",
       "      <td>van</td>\n",
       "      <td>white</td>\n",
       "      <td>https://images.craigslist.org/00x0x_lKicuXbjwb...</td>\n",
       "      <td>-See more vans at valuecargovans.com Price: $3...</td>\n",
       "      <td>None</td>\n",
       "      <td>tn</td>\n",
       "      <td>36.4641</td>\n",
       "      <td>-86.65828</td>\n",
       "      <td>2021-04-29T15:25:16-0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7316143261</td>\n",
       "      <td>https://ogden.craigslist.org/ctd/d/atlanta-201...</td>\n",
       "      <td>ogden-clearfield</td>\n",
       "      <td>https://ogden.craigslist.org</td>\n",
       "      <td>38990</td>\n",
       "      <td>2013</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>corvette grand sport</td>\n",
       "      <td>good</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>other</td>\n",
       "      <td>red</td>\n",
       "      <td>https://images.craigslist.org/00P0P_fxBYwOMmMp...</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>None</td>\n",
       "      <td>ut</td>\n",
       "      <td>33.779214</td>\n",
       "      <td>-84.411811</td>\n",
       "      <td>2021-05-03T07:14:49-0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7307668314</td>\n",
       "      <td>https://wyoming.craigslist.org/ctd/d/evans-201...</td>\n",
       "      <td>wyoming</td>\n",
       "      <td>https://wyoming.craigslist.org</td>\n",
       "      <td>39999</td>\n",
       "      <td>2015</td>\n",
       "      <td>ram</td>\n",
       "      <td>3500</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>pickup</td>\n",
       "      <td>None</td>\n",
       "      <td>https://images.craigslist.org/00r0r_BysOaosqN6...</td>\n",
       "      <td>\"2015 RAM 3500 4WD Crew Cab 169\"\" Laramie     ...</td>\n",
       "      <td>Inc — (970) 456-4813 or direct +19703306261 —...</td>\n",
       "      <td>999     2015 Gray 3500 Ram. 6.7 Litter CUMMINS...</td>\n",
       "      <td>Inc    Year: 2015 Make: RAM Model: 3500 Serie...</td>\n",
       "      <td>371  Exterior: Gray Interior: Black Body: Truc...</td>\n",
       "      <td>CO 80620   Phone: (970) 456-4813     Direct: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7316473997</td>\n",
       "      <td>https://baltimore.craigslist.org/ctd/d/baltimo...</td>\n",
       "      <td>baltimore</td>\n",
       "      <td>https://baltimore.craigslist.org</td>\n",
       "      <td>21590</td>\n",
       "      <td>2012</td>\n",
       "      <td>jaguar</td>\n",
       "      <td>xf portfolio sedan 4d</td>\n",
       "      <td>good</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>sedan</td>\n",
       "      <td>blue</td>\n",
       "      <td>https://images.craigslist.org/00R0R_lwWjXSEWNa...</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>None</td>\n",
       "      <td>md</td>\n",
       "      <td>39.3</td>\n",
       "      <td>-76.61</td>\n",
       "      <td>2021-05-03T18:30:53-0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7313883787</td>\n",
       "      <td>https://detroit.craigslist.org/mcb/ctd/d/harri...</td>\n",
       "      <td>detroit metro</td>\n",
       "      <td>https://detroit.craigslist.org</td>\n",
       "      <td>28590</td>\n",
       "      <td>2019</td>\n",
       "      <td>fiat</td>\n",
       "      <td>124 spider abarth</td>\n",
       "      <td>good</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>other</td>\n",
       "      <td>black</td>\n",
       "      <td>https://images.craigslist.org/00U0U_iSQWhP2Gt0...</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>None</td>\n",
       "      <td>mi</td>\n",
       "      <td>42.58</td>\n",
       "      <td>-82.81</td>\n",
       "      <td>2021-04-28T12:41:17-0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7304801711</td>\n",
       "      <td>https://bellingham.craigslist.org/ctd/d/bellin...</td>\n",
       "      <td>bellingham</td>\n",
       "      <td>https://bellingham.craigslist.org</td>\n",
       "      <td>37499</td>\n",
       "      <td>2016</td>\n",
       "      <td>ram</td>\n",
       "      <td>1500</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>pickup</td>\n",
       "      <td>black</td>\n",
       "      <td>https://images.craigslist.org/00B0B_kD6FJIqRiF...</td>\n",
       "      <td>2016 Ram 1500 Laramie Longhorn     Offered by:...</td>\n",
       "      <td>None</td>\n",
       "      <td>wa</td>\n",
       "      <td>48.756909</td>\n",
       "      <td>-122.452132</td>\n",
       "      <td>2021-04-10T11:29:04-0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7305260762</td>\n",
       "      <td>https://columbia.craigslist.org/ctd/d/mercedes...</td>\n",
       "      <td>columbia</td>\n",
       "      <td>https://columbia.craigslist.org</td>\n",
       "      <td>26998</td>\n",
       "      <td>2016</td>\n",
       "      <td>mercedes-benz</td>\n",
       "      <td>metris</td>\n",
       "      <td>None</td>\n",
       "      <td>4 cylinders</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>van</td>\n",
       "      <td>brown</td>\n",
       "      <td>https://images.craigslist.org/00A0A_hkj7yNP1AD...</td>\n",
       "      <td>\"2016 Mercedes Benz Metris Conversion Van High...</td>\n",
       "      <td>Dual Sliding Doors in the back.  Rare Mini Va...</td>\n",
       "      <td>540[C03] Active Safety Plus PackageBlind Spot ...</td>\n",
       "      <td>680[963] Indium Grey Metallic\\t$990[HH4] Therm...</td>\n",
       "      <td>Right\\t$740[T56] Electrical Operation Of Slid...</td>\n",
       "      <td>Left\\t$740[W65] Tailgate\\t$450Original Shippi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7303344920</td>\n",
       "      <td>https://greenville.craigslist.org/ctd/d/greenv...</td>\n",
       "      <td>greenville / upstate</td>\n",
       "      <td>https://greenville.craigslist.org</td>\n",
       "      <td>49990</td>\n",
       "      <td>2020</td>\n",
       "      <td>gmc</td>\n",
       "      <td>yukon slt sport utility 4d</td>\n",
       "      <td>good</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>SUV</td>\n",
       "      <td>black</td>\n",
       "      <td>https://images.craigslist.org/00X0X_3bMHmcFfx4...</td>\n",
       "      <td>Carvana is the safer way to buy a car During t...</td>\n",
       "      <td>None</td>\n",
       "      <td>sc</td>\n",
       "      <td>34.83</td>\n",
       "      <td>-82.37</td>\n",
       "      <td>2021-04-07T17:10:46-0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7306385685</td>\n",
       "      <td>https://pullman.craigslist.org/ctd/d/pullman-2...</td>\n",
       "      <td>pullman / moscow</td>\n",
       "      <td>https://pullman.craigslist.org</td>\n",
       "      <td>14988</td>\n",
       "      <td>2014</td>\n",
       "      <td>nissan</td>\n",
       "      <td>juke cvt nismo rs</td>\n",
       "      <td>like new</td>\n",
       "      <td>4 cylinders</td>\n",
       "      <td>...</td>\n",
       "      <td>compact</td>\n",
       "      <td>SUV</td>\n",
       "      <td>silver</td>\n",
       "      <td>https://images.craigslist.org/01717_gIUfTwAqG0...</td>\n",
       "      <td>2014 Nissan Juke CVT NISMO RS  *ENGINE: 1.6L I...</td>\n",
       "      <td>None</td>\n",
       "      <td>id</td>\n",
       "      <td>46.715081</td>\n",
       "      <td>-117.179896</td>\n",
       "      <td>2021-04-13T14:22:19-0700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                                url  \\\n",
       "13  7309153014  https://omaha.craigslist.org/ctd/d/council-blu...   \n",
       "35  7314502745  https://nashville.craigslist.org/ctd/d/white-h...   \n",
       "37  7316143261  https://ogden.craigslist.org/ctd/d/atlanta-201...   \n",
       "47  7307668314  https://wyoming.craigslist.org/ctd/d/evans-201...   \n",
       "16  7316473997  https://baltimore.craigslist.org/ctd/d/baltimo...   \n",
       "18  7313883787  https://detroit.craigslist.org/mcb/ctd/d/harri...   \n",
       "40  7304801711  https://bellingham.craigslist.org/ctd/d/bellin...   \n",
       "32  7305260762  https://columbia.craigslist.org/ctd/d/mercedes...   \n",
       "33  7303344920  https://greenville.craigslist.org/ctd/d/greenv...   \n",
       "10  7306385685  https://pullman.craigslist.org/ctd/d/pullman-2...   \n",
       "\n",
       "                    region                         region_url  price  year  \\\n",
       "13  omaha / council bluffs       https://omaha.craigslist.org   7495  2010   \n",
       "35               nashville   https://nashville.craigslist.org  32900  2019   \n",
       "37        ogden-clearfield       https://ogden.craigslist.org  38990  2013   \n",
       "47                 wyoming     https://wyoming.craigslist.org  39999  2015   \n",
       "16               baltimore   https://baltimore.craigslist.org  21590  2012   \n",
       "18           detroit metro     https://detroit.craigslist.org  28590  2019   \n",
       "40              bellingham  https://bellingham.craigslist.org  37499  2016   \n",
       "32                columbia    https://columbia.craigslist.org  26998  2016   \n",
       "33    greenville / upstate  https://greenville.craigslist.org  49990  2020   \n",
       "10        pullman / moscow     https://pullman.craigslist.org  14988  2014   \n",
       "\n",
       "     manufacturer                       model condition    cylinders  ...  \\\n",
       "13          honda                 civic sedan      None  4 cylinders  ...   \n",
       "35           ford                     transit  like new  6 cylinders  ...   \n",
       "37      chevrolet        corvette grand sport      good  8 cylinders  ...   \n",
       "47            ram                        3500      None         None  ...   \n",
       "16         jaguar       xf portfolio sedan 4d      good  8 cylinders  ...   \n",
       "18           fiat           124 spider abarth      good         None  ...   \n",
       "40            ram                        1500      None         None  ...   \n",
       "32  mercedes-benz                      metris      None  4 cylinders  ...   \n",
       "33            gmc  yukon slt sport utility 4d      good  8 cylinders  ...   \n",
       "10         nissan           juke cvt nismo rs  like new  4 cylinders  ...   \n",
       "\n",
       "         size    type paint_color  \\\n",
       "13       None   sedan       black   \n",
       "35  full-size     van       white   \n",
       "37       None   other         red   \n",
       "47       None  pickup        None   \n",
       "16       None   sedan        blue   \n",
       "18       None   other       black   \n",
       "40       None  pickup       black   \n",
       "32       None     van       brown   \n",
       "33       None     SUV       black   \n",
       "10    compact     SUV      silver   \n",
       "\n",
       "                                            image_url  \\\n",
       "13  https://images.craigslist.org/00o0o_fspI4HDewO...   \n",
       "35  https://images.craigslist.org/00x0x_lKicuXbjwb...   \n",
       "37  https://images.craigslist.org/00P0P_fxBYwOMmMp...   \n",
       "47  https://images.craigslist.org/00r0r_BysOaosqN6...   \n",
       "16  https://images.craigslist.org/00R0R_lwWjXSEWNa...   \n",
       "18  https://images.craigslist.org/00U0U_iSQWhP2Gt0...   \n",
       "40  https://images.craigslist.org/00B0B_kD6FJIqRiF...   \n",
       "32  https://images.craigslist.org/00A0A_hkj7yNP1AD...   \n",
       "33  https://images.craigslist.org/00X0X_3bMHmcFfx4...   \n",
       "10  https://images.craigslist.org/01717_gIUfTwAqG0...   \n",
       "\n",
       "                                          description  \\\n",
       "13  2010 *Honda* *Civic Sedan* 4dr Automatic LX-S ...   \n",
       "35  -See more vans at valuecargovans.com Price: $3...   \n",
       "37  Carvana is the safer way to buy a car During t...   \n",
       "47  \"2015 RAM 3500 4WD Crew Cab 169\"\" Laramie     ...   \n",
       "16  Carvana is the safer way to buy a car During t...   \n",
       "18  Carvana is the safer way to buy a car During t...   \n",
       "40  2016 Ram 1500 Laramie Longhorn     Offered by:...   \n",
       "32  \"2016 Mercedes Benz Metris Conversion Van High...   \n",
       "33  Carvana is the safer way to buy a car During t...   \n",
       "10  2014 Nissan Juke CVT NISMO RS  *ENGINE: 1.6L I...   \n",
       "\n",
       "                                               county  \\\n",
       "13                                               None   \n",
       "35                                               None   \n",
       "37                                               None   \n",
       "47   Inc — (970) 456-4813 or direct +19703306261 —...   \n",
       "16                                               None   \n",
       "18                                               None   \n",
       "40                                               None   \n",
       "32   Dual Sliding Doors in the back.  Rare Mini Va...   \n",
       "33                                               None   \n",
       "10                                               None   \n",
       "\n",
       "                                                state  \\\n",
       "13                                                 ia   \n",
       "35                                                 tn   \n",
       "37                                                 ut   \n",
       "47  999     2015 Gray 3500 Ram. 6.7 Litter CUMMINS...   \n",
       "16                                                 md   \n",
       "18                                                 mi   \n",
       "40                                                 wa   \n",
       "32  540[C03] Active Safety Plus PackageBlind Spot ...   \n",
       "33                                                 sc   \n",
       "10                                                 id   \n",
       "\n",
       "                                                  lat  \\\n",
       "13                                          41.229172   \n",
       "35                                            36.4641   \n",
       "37                                          33.779214   \n",
       "47   Inc    Year: 2015 Make: RAM Model: 3500 Serie...   \n",
       "16                                               39.3   \n",
       "18                                              42.58   \n",
       "40                                          48.756909   \n",
       "32  680[963] Indium Grey Metallic\\t$990[HH4] Therm...   \n",
       "33                                              34.83   \n",
       "10                                          46.715081   \n",
       "\n",
       "                                                 long  \\\n",
       "13                                         -95.852118   \n",
       "35                                          -86.65828   \n",
       "37                                         -84.411811   \n",
       "47  371  Exterior: Gray Interior: Black Body: Truc...   \n",
       "16                                             -76.61   \n",
       "18                                             -82.81   \n",
       "40                                        -122.452132   \n",
       "32   Right\\t$740[T56] Electrical Operation Of Slid...   \n",
       "33                                             -82.37   \n",
       "10                                        -117.179896   \n",
       "\n",
       "                                         posting_date  \n",
       "13                           2021-04-19T07:21:13-0500  \n",
       "35                           2021-04-29T15:25:16-0500  \n",
       "37                           2021-05-03T07:14:49-0600  \n",
       "47   CO 80620   Phone: (970) 456-4813     Direct: ...  \n",
       "16                           2021-05-03T18:30:53-0400  \n",
       "18                           2021-04-28T12:41:17-0400  \n",
       "40                           2021-04-10T11:29:04-0700  \n",
       "32   Left\\t$740[W65] Tailgate\\t$450Original Shippi...  \n",
       "33                           2021-04-07T17:10:46-0400  \n",
       "10                           2021-04-13T14:22:19-0700  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carsdata.sample(False,0.0001,10).toPandas().sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic statistics on raw dataset columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "|summary|              region|               state|                year|                 lat|     long|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "|  count|              434901|              418725|              433912|              416405|   417087|\n",
      "|   mean|   1427.686274509804|  1697.5362095531586|  2005.5686682071973|   41.77550324222822| Infinity|\n",
      "| stddev|   808.3057161506485|   737.2614799468287|  112.05149237025323|   84.63443683901487|      NaN|\n",
      "|    min|               1500 |                 ...| $489 Doc charge ...|                    |         |\n",
      "|    max|zanesville / camb...|           blindspot|                  wa|🌟  Color: Sandal...|” however|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+--------------------+-----------------+-----------------+\n",
      "|summary|     manufacturer|               model|               price|        condition|         odometer|\n",
      "+-------+-----------------+--------------------+--------------------+-----------------+-----------------+\n",
      "|  count|           412865|              424296|              435356|           254659|           424001|\n",
      "|   mean|744.1736842578244|  1914.5716864965727|    74186.5376440274|549.0233284319527|98034.05423732463|\n",
      "| stddev|1029.712929811658|   5327.649155487644|1.2099967417236006E7|959.2700455051272|213873.5016305289|\n",
      "|    min|             2010|                2007|                    |             2006|     BMW 3 Series|\n",
      "|    max|            volvo|🔥GMC Sierra 1500...|                  wa|          salvage|               wa|\n",
      "+-------+-----------------+--------------------+--------------------+-----------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------------+------------------+------+------------------+------------------+\n",
      "|summary|cylinders|              fuel|      transmission| drive|              size|              type|\n",
      "+-------+---------+------------------+------------------+------+------------------+------------------+\n",
      "|  count|   251004|            425458|            425870|297624|            121805|            334910|\n",
      "|   mean|   2005.0|1797.1560693641618| 368.7826138090185| 545.0| 424.0317873538461|479.85442769230747|\n",
      "| stddev|      0.0|248.64087282720493|173.93991068794728|   0.0|203.03621112166982|316.42065528497534|\n",
      "|    min|     2005|              1500|              250 |   545|               530|               645|\n",
      "|    max|    other|                wa|             other|   rwd|       sub-compact|             wagon|\n",
      "+-------+---------+------------------+------------------+------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------------+-----------------+------------------+--------------------+\n",
      "|summary|                 url|     title_status|              vin|       paint_color|           image_url|\n",
      "+-------+--------------------+-----------------+-----------------+------------------+--------------------+\n",
      "|  count|              431918|           420184|           267316|            297963|              428070|\n",
      "|   mean|  1406.3489361702127| 322.347487744898|         Infinity|1054.8554913294797|   466.3659410647941|\n",
      "| stddev|   919.4004721287523|214.1420067328583|              NaN| 372.4679741756739|   815.1995906348874|\n",
      "|    min|      2005 Subaru...|             150 |             350 |             1500 |               2500 |\n",
      "|    max|https://zanesvill...|          salvage|ZPBUA1ZL1KLA02237|            yellow|https://images.cr...|\n",
      "+-------+--------------------+-----------------+-----------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "carsdata.select(\"region\",\"state\",\"year\",\"lat\",\"long\").describe().show()\n",
    "carsdata.select(\"manufacturer\",\"model\",\"price\",\"condition\",\"odometer\").describe().show()\n",
    "carsdata.select(\"cylinders\",\"fuel\",\"transmission\",\"drive\",\"size\",\"type\").describe().show()\n",
    "carsdata.select(\"url\",\"title_status\",\"vin\",\"paint_color\",\"image_url\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, the `.describe()` or `.explain()` method is a good way to start exploring a dataset. For this dataset, there are too many columns, some very unclean, and it is hard to decipher much from the above results. <br>\n",
    "\n",
    "For this project, we will perform cleaning twice. The Extract stage has a basic cleaning section to remove duplicates and to obtain numerical features (notice in the schema above, all columns are *String* by default). We can cache the Extracted Data in a compressed format such as parquet, so it can be used for different pipelines. <br>\n",
    "\n",
    "The main cleaning section is performed during the [Transform Stage](#Transform-Data).<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data (Basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of **Extract Stage** cleaning is to find a balance between cleaning the data and maintaining the maximum amount of raw data. This optimizes usability for other pipelines. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scraper can't find duplicate recors because of various reasons. Each duplicate is more likely the result of people posting multiple times or other errors. Therefore no record from the raw dataset can be found to be a complete duplicate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, duplicates can be removed by excluding `url` when calling .drop_duplicates() on **`vehicle_listings`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'url', 'region', 'region_url', 'price', 'year', 'manufacturer', 'model', 'condition', 'cylinders', 'fuel', 'odometer', 'title_status', 'transmission', 'VIN', 'drive', 'size', 'type', 'paint_color', 'image_url', 'description', 'county', 'state', 'lat', 'long', 'posting_date']\n"
     ]
    }
   ],
   "source": [
    "print(carsdata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_carsdata=carsdata.drop_duplicates(['region', 'price', 'year', 'manufacturer', 'model', 'condition', 'cylinders', 'fuel', 'odometer', 'title_status', 'transmission', 'vin', 'drive', 'size', 'type', 'paint_color', 'image_url', 'lat', 'long'])\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Numerical Columns\n",
    "Convert *numerical feature types* from string to float to obtain **Numerical** data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- region_url: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- manufacturer: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- cylinders: string (nullable = true)\n",
      " |-- fuel: string (nullable = true)\n",
      " |-- odometer: string (nullable = true)\n",
      " |-- title_status: string (nullable = true)\n",
      " |-- transmission: string (nullable = true)\n",
      " |-- VIN: string (nullable = true)\n",
      " |-- drive: string (nullable = true)\n",
      " |-- size: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- paint_color: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- lat: string (nullable = true)\n",
      " |-- long: string (nullable = true)\n",
      " |-- posting_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cols=[\"price\",\"year\",\"odometer\"]\n",
    "\n",
    "clean_carsdara = (reduce(\n",
    "            lambda memo_df, col_name: memo_df.withColumn(col_name, carsdata[col_name].cast(\"float\")),\n",
    "            cols,\n",
    "            clean_carsdata))\n",
    "\n",
    "clean_carsdata.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching Extract Data on S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning, the final task in the **Extract** stage is to cache the data. I will store the cleaned dataset as a parquet file on Amazon S3. We can return to this file without having to run the Extract pipeline again, and attach other pipelines from this point as well. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>NOTE</b> This implementation uses .coalesce(4) before .write() to optimize read/write performance on S3.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#let us save data as parquet \n",
    "clean_carsdata.coalesce(4).write.parquet(\"cardata_extraction.parquet\",mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unable to connect to S3 directly using SparkSession due to Spark generating its credentials, possibly due to versioning... <br>\n",
    "Instead, we can connect to S3 using a bash script.<br>\n",
    "The parquet compression brings the file size down to *<30MB*, so this doesn't cause performance issues here.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to AWS S3...\n",
      "Object Written to S3.\n",
      "S3 Bucket Contents\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "Writing files to S3 Bucket...\n",
      "upload: cardata_extraction.parquet/._SUCCESS.crc to s3://kiboma/cardata/extract/._SUCCESS.crc\n",
      "upload: cardata_extraction.parquet/_SUCCESS to s3://kiboma/cardata/extract/_SUCCESS\n",
      "upload: cardata_extraction.parquet/.part-00003-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc to s3://kiboma/cardata/extract/.part-00003-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc\n",
      "upload: cardata_extraction.parquet/.part-00002-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc to s3://kiboma/cardata/extract/.part-00002-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc\n",
      "upload: cardata_extraction.parquet/.part-00001-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc to s3://kiboma/cardata/extract/.part-00001-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc\n",
      "upload: cardata_extraction.parquet/.part-00000-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc to s3://kiboma/cardata/extract/.part-00000-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc\n",
      "upload: cardata_extraction.parquet/part-00003-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet to s3://kiboma/cardata/extract/part-00003-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet\n",
      "upload: cardata_extraction.parquet/part-00002-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet to s3://kiboma/cardata/extract/part-00002-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet\n",
      "upload: cardata_extraction.parquet/part-00000-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet to s3://kiboma/cardata/extract/part-00000-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet\n",
      "upload: cardata_extraction.parquet/part-00001-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet to s3://kiboma/cardata/extract/part-00001-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet\n",
      "Write complete.\n",
      "---------------------------------\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print (\"Connecting to AWS S3...\")\n",
    "subprocess.Popen(['./kiboma.command','write_extract'])\n",
    "print (\"Object Written to S3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes the **Extract Stage**. <br>\n",
    "\n",
    "We clean, sample and explore the data in the **Transform Stage**. The data available on S3 is clean but as close to the raw data as possible. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*First we obtain the working dataset from the cached source on S3.* <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to AWS S3...\n",
      "Object Read from S3 to ..Home Dir.\n",
      "S3 Bucket Contents\n",
      "---------------------------------\n",
      "                           PRE cardata/\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "Reading files from S3 Bucket...\n",
      "download: s3://kiboma/cardata/extract/._SUCCESS.crc to cardata_extrct_dowload.parquet/._SUCCESS.crc\n",
      "download: s3://kiboma/cardata/extract/_SUCCESS to cardata_extrct_dowload.parquet/_SUCCESS\n",
      "download: s3://kiboma/cardata/extract/.part-00003-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc to cardata_extrct_dowload.parquet/.part-00003-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc\n",
      "download: s3://kiboma/cardata/extract/.part-00001-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc to cardata_extrct_dowload.parquet/.part-00001-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc\n",
      "download: s3://kiboma/cardata/extract/.part-00000-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc to cardata_extrct_dowload.parquet/.part-00000-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc\n",
      "download: s3://kiboma/cardata/extract/.part-00002-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc to cardata_extrct_dowload.parquet/.part-00002-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet.crc\n",
      "download: s3://kiboma/cardata/extract/part-00003-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet to cardata_extrct_dowload.parquet/part-00003-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet\n",
      "download: s3://kiboma/cardata/extract/part-00000-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet to cardata_extrct_dowload.parquet/part-00000-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet\n",
      "download: s3://kiboma/cardata/extract/part-00002-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet to cardata_extrct_dowload.parquet/part-00002-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet\n",
      "download: s3://kiboma/cardata/extract/part-00001-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet to cardata_extrct_dowload.parquet/part-00001-61966c59-cdbf-426c-87ec-e1a037471778-c000.snappy.parquet\n",
      "Read complete.\n",
      "---------------------------------\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print (\"Connecting to AWS S3...\")\n",
    "subprocess.Popen(['./kiboma.command','read_extract'])\n",
    "print (\"Object Read from S3 to ..Home Dir.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vehicles_listings_read=spark.read.parquet(\"s3a://s3://kiboma/usedcars/extract\")\n",
    "#vehicle_listings_read=spark.read.parquet(\"S3_cardata.parquet\")\n",
    "\n",
    "clean_carsdata = spark.read.format(\"parquet\").option(\"inferschema\",\"true\").load(\"cardata_extrct_dowload.parquet\")\n",
    "type(clean_carsdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 22:>                                                         (0 + 4) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382307 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(clean_carsdata.count(),len(clean_carsdata.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are over 1.5 million records, and 26 columns. The dataset is too large to perform EDA (Exploratory Data Analysis) comfortably. <br>\n",
    "The final data after *Cleaning* should be as clean as possible without redundant data.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning is essential during the **Transform Stage** of the ETL pipeline. The main goal here is to optimize the dataset for the endgoal of the project - Creating a machine learning pipeline to predict the target varibale **Price**. <br>\n",
    "\n",
    "We can also cache the cleaned data set before sampling and exploration for other machine learning project using the same dataset.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Checkpoints\n",
    "\n",
    "+  General\n",
    "    +  Drop Columns\n",
    "    +  Drop Rows (Null Price)\n",
    "+  Numerical \n",
    "    +  Apply Reasonable Ranges\n",
    "        +  Kept Odometer Null Values\n",
    "+  Ordinal\n",
    "    +  Narrow down relevant options\n",
    "    +  Remove errors in columns\n",
    "    +  Keep countable ordinal values\n",
    "+  Categorical\n",
    "    +  State_code + State_name (Extract Stage)\n",
    "        +  Removed State_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Columns\n",
    "\n",
    "Some Columns are redundant, we can remove them before moving forward.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['region', 'price', 'year', 'manufacturer', 'model', 'condition', 'cylinders', 'fuel', 'odometer', 'title_status', 'transmission', 'drive', 'size', 'type', 'county', 'state']\n"
     ]
    }
   ],
   "source": [
    "clean_carsdata=clean_carsdata.drop('url','region_url','vin', 'paint_color', 'image_url', \\\n",
    "                                       'lat', 'long', 'id', 'posting_date','description')\n",
    "print(clean_carsdata.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'lat' and 'long' provide no more useful information than ('city','county_name', 'state_code', 'state_name'), and are therefore not needed.<br>\n",
    "The other dropped columns are not helpful to the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining attribute characteristics are varied, we have three types of features available in our data -\n",
    "**Numerical**, **Ordinal**, **Categorical**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Potential Column Types -** <br>\n",
    "Numerical - price, year, odometer <br>\n",
    "Ordinal - condition, cylinders, fuel, title_status, transmission, drive, size, type <br>\n",
    "Categorical - city, manufacturer, make, county_name, state_code, state_name <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable of this project is **Price**. Therefore, any records where price is null would be irrelevant. Check to see if the dataset contains null prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 25:>                                                         (0 + 4) / 5]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_carsdata.filter(clean_carsdata.price.isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Data Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is numerial data in the database\n",
    "Num=[\"price\",\"manufacturer\",\"model\",\"region\",\"odometer\",\"year\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying a Reasonable Range on Continuous Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Website postings that advertise items for sale often manipulate search algorithms to get more hits. For example, thousands of posts are spammed with a price of $1 (minimum allowed), to get more visibility through the 'search by price' filter. To ensure that our working dataset is within reasonable boundaries, we apply restrictions on the *Continuous* data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data: 43169\n",
      "Old data: 1404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expensive cars: 56\n",
      "Cheap cars: 34063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 40:==============================================>           (4 + 1) / 5]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many miles: 6465\n",
      "few miles: 5484\n"
     ]
    }
   ],
   "source": [
    "print(\"New data: %d\" %clean_carsdata.where(\"year >= 2019\").count())\n",
    "print(\"Old data: %d\" %clean_carsdata.where(\"year < 1930\").count())\n",
    "print(\"Expensive cars: %d\" %clean_carsdata.where(\"price > 300000\").count())\n",
    "print(\"Cheap cars: %d\" %clean_carsdata.where(\"price < 50\").count())\n",
    "print(\"Many miles: %d\" %clean_carsdata.where(\"odometer > 250000\").count())\n",
    "print(\"few miles: %d\" %clean_carsdata.where(\"odometer < 50\").count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before removing 20k+ records due to price, let's confirm if the spame hypothesis is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 46:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+--------------------+--------+--------------------+\n",
      "|     price| manufacturer|               model|              region|odometer|                year|\n",
      "+----------+-------------+--------------------+--------------------+--------+--------------------+\n",
      "| -77.49321|         null|                null|                  va|    null|2021-04-23T06:02:...|\n",
      "|         0|         null|                 all|         san antonio|   12345|                2020|\n",
      "|         0|      hyundai|              tucson|         long island|   69495|                2017|\n",
      "|         0|    chevrolet|    silverado 2500hd|          charleston|   86534|                2016|\n",
      "|         0|mercedes-benz|             m-class|raleigh / durham ...|   94809|                2013|\n",
      "|         0|       toyota|         prius+prime|         long island|   70179|                2017|\n",
      "|         0|        honda|              accord|       winston-salem|  133837|                2003|\n",
      "|         0|         ford|               e-350|ft myers / SW flo...|    null|                2010|\n",
      "|         0|          bmw|                  m5|             madison|    null|                2007|\n",
      "|         0|          kia|              optima|            richmond|   68110|                2016|\n",
      "|         0|       toyota|             corolla|               boise|   24185|                2020|\n",
      "|         0|         ford|            explorer|              albany|   64000|                2016|\n",
      "|         0|        dodge|          charger se|         san antonio|   56960|                2014|\n",
      "|         0|      hyundai|             elantra|          san marcos|   47003|                2018|\n",
      "|-74.042702|         null|                null|                  pa|    null|2021-04-15T18:31:...|\n",
      "|-82.660598|         null|                null|                  oh|    null|2021-04-14T17:08:...|\n",
      "|         0|       toyota|4runner limited 4...|kennewick-pasco-r...|   45151|                2017|\n",
      "|         0|    chevrolet|       cruze limited|     fresno / madera|   94127|                2016|\n",
      "|         0|         ford|f-350 super duty ...|               chico|  101667|                2016|\n",
      "|         0|        buick|             enclave|        south jersey|  111398|                2012|\n",
      "+----------+-------------+--------------------+--------------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_carsdata.sample(False,0.001,100).where(\"price<50\").select(Num).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, these randomly obtained results show us that \"price<50\" is not very useful to the study. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mising values of odometer : 9813\n",
      "Missing values price : 51\n",
      "Missing values of  year : 1239\n"
     ]
    }
   ],
   "source": [
    "print(\"Mising values of odometer :\",clean_carsdata.filter(clean_carsdata.odometer.isNull()).count())\n",
    "print(\"Missing values price :\",clean_carsdata.filter(clean_carsdata.price.isNull()).count())\n",
    "print(\"Missing values of  year :\",clean_carsdata.filter(clean_carsdata.year.isNull()).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Null counts shows us that a lot of listings have not reported Odometer values, perhaps to increase chances of selling a car or maybe due to lack of info. The question is, do we remove all these records altogether?<br>\n",
    "I would rather keep these records because the 50k+ rows will still provide useful information about other attributes. Removing these values would reduce the dataset by 35%, which is too high.<br>\n",
    "<br>Apply the restrictions to vehicle_listings_clean.<br>\n",
    "Note- The Spark environment allows me to use a direct SQL query to restrict odometer values. This is better suited because the **`pyspark.sql.dataframe`** library treats \"null\" values as false when evaluating the `.where()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/pyspark/sql/dataframe.py:138: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original dataset  441802\n",
      "range  298061\n",
      " 67 percent number of data stored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:==================================>                       (3 + 2) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|             price|              year|          odometer|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|            298061|            298061|            296406|\n",
      "|   mean|  17268.8696911035|2010.1089609173962| 98653.14427508214|\n",
      "| stddev|13711.733852783767| 9.415662197252933|56955.964519133726|\n",
      "|    min|               100|              1930|               100|\n",
      "|    max|             99999|              2018|             99999|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "clean_carsdata = clean_carsdata.where(\"price>=50 and price<=300000\").where(\"year>=1930 and year<2019\") \n",
    "\n",
    "clean_carsdata.registerTempTable(\"df_temp\")\n",
    "\n",
    "clean_carsdata=spark.sql(\"SELECT * FROM df_temp WHERE (odometer>=50 AND odometer<=250000) OR (odometer IS NULL)\")\n",
    "\n",
    "main=carsdata.count()\n",
    "recent=clean_carsdata.count()\n",
    "\n",
    "print(\"Number of original dataset \",main)\n",
    "print(\"range \",recent)\n",
    "print(\" %d percent number of data stored\" % (100 * recent / main))\n",
    "\n",
    "clean_carsdata.select(\"price\",\"year\",\"odometer\").describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although only 3 attributes, **price, year, odometer**, can be directly converted to numerical value, other attributes can be be transformed to fit the Categorical and Ordinal labels. The difference between categorical and ordinal values is that ordinal values have a clear and restricted ordering of types. For example, *'condition'* would be ordinal, ranging from excellent to poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Data Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinal data will play an important role in learning about price. An ordinal data type is a variable that has a limited number of options, which can be ordered. For example, `\"condition\"` should range from excellent to bad (or in this case, \"salvage\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following columns are of the **Ordinal** types -  <br>\n",
    "(condition, cylinders, fuel, title_status, transmission, drive, size, type) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ordinals_options_all`** is a map linking each ordinal to each distinct value provided for it. This will help cleaning the dataset faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[condition: string, cylinders: string, fuel: string, title_status: string, transmission: string, drive: string, size: string, type: string]\n"
     ]
    }
   ],
   "source": [
    "ordcolumns=clean_carsdata['condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'size', 'type']\n",
    "print(ordcolumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, all 8 Ordinal columns have values that seem to be errors, or reported incorrectly. For example, let's look into the \"Condition\" reported as 'like new\"'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+-----+------+--------+----+---------+\n",
      "|price|manufacturer|model|region|odometer|year|condition|\n",
      "+-----+------------+-----+------+--------+----+---------+\n",
      "+-----+------------+-----+------+--------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_carsdata.filter(\"condition = 'like new\\\"'\" ).select(Num+[\"condition\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 1 record fetched. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next task is to clean these misleading values for each of the ordinal types. Automating this process, at the very least requires two `pyspark.sql.dataframe` library calls for each distinct ordinal option - `count()` and `replace()`. We can count the number of occurences of a value in an ordinal column, if it's less than 10 then it is  irrelevant and will be grouped under \"other\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`remove_fakes()`** is a function that takes in a column and all distinct values within the column, and evaluates which options are useful. It bunches up other options under \"Other\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Cost - Each call to **`remove_fakes()`** will take **O(n)** *(O(2n+1))* where *n* is the length of the column. Because the algorithm needs to call both `count()` and `replace()` for any ordinal/value combination, this is the fastest way to clean the ordinal columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function does not count *null* values. The difference between values printed as a list after the clean versus the final `count()` value are *null* and, in some cases, *other*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning column = 'condition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(clean_carsdata.select(\"condition\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning column = 'cylinders'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number for cylinders 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Number for cylinders\",clean_carsdata.select(\"cylinders\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning column = 'fuel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number for fuel 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Number for fuel\",clean_carsdata.select(\"fuel\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning column = 'title_status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 120:===========>                                             (1 + 4) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number for 'title_status'- 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Number for 'title_status'-\",clean_carsdata.select(\"title_status\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning column = 'transmission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number for 'transmission'-\",clean_carsdata.select(\"transmission\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning column = 'drive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 126:=============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number for 'drive'- 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Number for 'drive'-\",clean_carsdata.select(\"drive\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning column = 'size'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 132:==================================>                      (3 + 2) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number for 'size'- 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Number for 'size'-\",clean_carsdata.select(\"size\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning column = 'type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 138:>                                                        (0 + 4) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number for 'type'- 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Number for 'type'-\",clean_carsdata.select(\"type\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Data Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical - city, manufacturer, make, county_name, state_code, state_name <br>\n",
    "\n",
    "During the **Transform** stage, categorical columns will help with *Stratified Sampling* before beginning with Exploratory Data Analysis... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't much cleaning to be done with categorical data. An easy observation is that this set of columns give us insight about location unlike other column types. There might be a way to combine state_code and state_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 145:>                                                        (0 + 3) / 3]\r",
      "\r",
      "[Stage 145:======================================>                  (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|              region|              county|               state|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|saginaw-midland-b...|                null|                  mi|\n",
      "|            portland|                null|                  or|\n",
      "|        jacksonville|                null|                  nc|\n",
      "|dayton / springfield|                null|                  oh|\n",
      "|             buffalo|                null|                  ny|\n",
      "|          las cruces|                null|                  nm|\n",
      "|         los angeles| CA today! We wan...| CA! We stock man...|\n",
      "|          sacramento|                null|                  ca|\n",
      "|             boulder|                null|                  co|\n",
      "|           catskills|                null|                  ny|\n",
      "|             phoenix|                null|                  az|\n",
      "|    champaign urbana|                null|                  il|\n",
      "|         springfield|                null|                  mo|\n",
      "|        oregon coast|                null|                  or|\n",
      "|              austin|                null|                  tx|\n",
      "|      seattle-tacoma|                null|                  wa|\n",
      "|           charlotte|         SIN LICENSI| NO CREDITO NO PR...|\n",
      "|           kalamazoo|                null|                  mi|\n",
      "|        fayetteville|                null|                  ar|\n",
      "|     medford-ashland|                null|                  or|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "clean_carsdata.select(\"region\",\"county\",\"state\").sample(False,0.0001,100).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that when state_code is *null*, the matching state_name is *Failed*. Since the state_name appears to be generated by state_code, there isn't any point in keeping both. Let's remove state_name. Our total columns are now 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dimensions -  441802 * 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Dimensions -  298061 * 16\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Dimensions - \",carsdata.count(),\"*\",len(carsdata.columns))\n",
    "print(\"New Dimensions - \",clean_carsdata.count(),\"*\",len(clean_carsdata.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final dataset size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 155:===========>                                             (1 + 4) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dimensions -  441802 * 26\n",
      "New Dimensions -  298061 * 16\n",
      "Data kept for analysis: 67 percent of records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 155:======================>                                  (2 + 3) / 5]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "old_col=carsdata.count()\n",
    "old_row=len(carsdata.columns)\n",
    "new_col=clean_carsdata.count()\n",
    "new_row=len(clean_carsdata.columns)\n",
    "\n",
    "print(\"Original Dimensions - \",old_col,\"*\",old_row)\n",
    "print(\"New Dimensions - \",new_col,\"*\",new_row)\n",
    "\n",
    "\n",
    "print(\"Data kept for analysis: %d percent of records\" % (100 * new_col / old_col))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The used cars dataset is now cleaned and ready for analysis. We can cache this version on S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "clean_carsdata.coalesce(4).write.parquet(\"clean_carsdata_transform.parquet\",mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to AWS S3...\n",
      "Object Written to S3.\n",
      "S3 Bucket Contents\n",
      "---------------------------------\n",
      "                           PRE cardata/\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "Writing files to S3 Bucket...\n",
      "upload: clean_carsdata_transform.parquet/_SUCCESS to s3://kiboma/cardata/transform/_SUCCESS\n",
      "upload: clean_carsdata_transform.parquet/._SUCCESS.crc to s3://kiboma/cardata/transform/._SUCCESS.crc\n",
      "upload: clean_carsdata_transform.parquet/.part-00003-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc to s3://kiboma/cardata/transform/.part-00003-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc\n",
      "upload: clean_carsdata_transform.parquet/.part-00000-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc to s3://kiboma/cardata/transform/.part-00000-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc\n",
      "upload: clean_carsdata_transform.parquet/.part-00001-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc to s3://kiboma/cardata/transform/.part-00001-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc\n",
      "upload: clean_carsdata_transform.parquet/.part-00002-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc to s3://kiboma/cardata/transform/.part-00002-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc\n",
      "upload: clean_carsdata_transform.parquet/part-00003-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet to s3://kiboma/cardata/transform/part-00003-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet\n",
      "upload: clean_carsdata_transform.parquet/part-00002-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet to s3://kiboma/cardata/transform/part-00002-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet\n",
      "upload: clean_carsdata_transform.parquet/part-00001-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet to s3://kiboma/cardata/transform/part-00001-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet\n",
      "upload: clean_carsdata_transform.parquet/part-00000-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet to s3://kiboma/cardata/transform/part-00000-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet\n",
      "Write complete.\n",
      "---------------------------------\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print (\"Connecting to AWS S3...\")\n",
    "subprocess.Popen(['./kiboma.command','write_transform'])\n",
    "print (\"Object Written to S3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*First we obtain the working dataset from the cached source on S3.* <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to AWS S3...\n",
      "Object Read from S3 to ..homedir.\n",
      "S3 Bucket Contents\n",
      "---------------------------------\n",
      "                           PRE cardata/\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "Reading files from S3 Bucket...\n",
      "download: s3://kiboma/cardata/transform/.part-00003-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc to cardata_transform.parquet/.part-00003-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc\n",
      "download: s3://kiboma/cardata/transform/._SUCCESS.crc to cardata_transform.parquet/._SUCCESS.crc\n",
      "download: s3://kiboma/cardata/transform/_SUCCESS to cardata_transform.parquet/_SUCCESS\n",
      "download: s3://kiboma/cardata/transform/.part-00002-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc to cardata_transform.parquet/.part-00002-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc\n",
      "download: s3://kiboma/cardata/transform/.part-00000-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc to cardata_transform.parquet/.part-00000-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc\n",
      "download: s3://kiboma/cardata/transform/.part-00001-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc to cardata_transform.parquet/.part-00001-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet.crc\n",
      "download: s3://kiboma/cardata/transform/part-00002-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet to cardata_transform.parquet/part-00002-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet\n",
      "download: s3://kiboma/cardata/transform/part-00003-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet to cardata_transform.parquet/part-00003-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet\n",
      "download: s3://kiboma/cardata/transform/part-00000-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet to cardata_transform.parquet/part-00000-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet\n",
      "download: s3://kiboma/cardata/transform/part-00001-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet to cardata_transform.parquet/part-00001-14381258-cadc-41f3-8829-78b027bd05dd-c000.snappy.parquet\n",
      "Read complete.\n",
      "---------------------------------\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print (\"Connecting to AWS S3...\")\n",
    "subprocess.Popen(['./kiboma.command','read_transform'])\n",
    "print (\"Object Read from S3 to ..homedir.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_carsdata = spark.read.format(\"parquet\").option(\"inferschema\",\"true\").load(\"cardata_transform.parquet\")\n",
    "type(clean_carsdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298061 16\n"
     ]
    }
   ],
   "source": [
    "print(clean_carsdata.count(),len(clean_carsdata.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the section, we will obtain features from the ordinal columns, in order to use the information for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[condition: string, cylinders: string, fuel: string, title_status: string, transmission: string, drive: string, size: string, type: string]\n"
     ]
    }
   ],
   "source": [
    "print(ordcolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_carsdata = clean_carsdata.fillna({'condition':'other'})\n",
    "clean_carsdata= clean_carsdata.fillna({'cylinders':'other'})\n",
    "clean_carsdata = clean_carsdata.fillna({'fuel':'other'})\n",
    "clean_carsdata = clean_carsdata.fillna({'title_status':'other'})\n",
    "clean_carsdata = clean_carsdata.fillna({'transmission':'other'})\n",
    "clean_carsdata = clean_carsdata.fillna({'drive':'other'})\n",
    "clean_carsdata = clean_carsdata.fillna({'size':'other'})\n",
    "clean_carsdata = clean_carsdata.fillna({'type':'other'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Indexer\n",
    "\n",
    "Using `StringIndexer`, convert ordinal column names to numerical values. It is import to retain the original columns track which index is assigned to which unique column option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "    StringIndexer(inputCol=c, outputCol='{}_index'.format(c))\n",
    "    for c in clean_carsdata.columns\n",
    "])\n",
    "\n",
    "clean_carsdata_features = pipeline.fit(clean_carsdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_carsdata_features.count(),len(clean_carsdata_features.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "\n",
    "Using `OneHotEncoder`, we can encode the ordinal column indexes.\n",
    "\n",
    "One-hot encoding maps a categorical feature, represented as a label index, to a binary vector with at most a single one-value indicating the presence of a specific feature value from among the set of all feature values. This encoding allows algorithms which expect continuous features, such as Logistic Regression, to use categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "encorder = Pipeline(stages=[\n",
    "   OneHotEncoder(inputCol=c, outputCol='{}_index'.format(c))\n",
    "    for c in clean_carsdata.columns\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new 8 columms of `vehicle_listings_encoded` are of type `vector`. This type can be recognized by Machine Learning models, so there is not need to extract each vector into separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_carsdata_encoded.count(),len(clean_carsdata_encoded.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Data\n",
    "\n",
    "<br>To explore the dataset for analysis, create a **sample pandas dataframe** from the engineered data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 62:==============>                                           (1 + 3) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ex_df=clean_carsdata.sample(False,0.001,63).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a small random sample of the Feature Engineered Data, we can take a look at what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>drive</th>\n",
       "      <th>size</th>\n",
       "      <th>type</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>long island</td>\n",
       "      <td>13695</td>\n",
       "      <td>2007</td>\n",
       "      <td>cadillac</td>\n",
       "      <td>escalade</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>gas</td>\n",
       "      <td>144492</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>None</td>\n",
       "      <td>SUV</td>\n",
       "      <td>None</td>\n",
       "      <td>ny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lakeland</td>\n",
       "      <td>40990</td>\n",
       "      <td>2017</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>silverado 1500</td>\n",
       "      <td>excellent</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>47021</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>pickup</td>\n",
       "      <td>None</td>\n",
       "      <td>fl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tulsa</td>\n",
       "      <td>28999</td>\n",
       "      <td>2018</td>\n",
       "      <td>ford</td>\n",
       "      <td>f-150</td>\n",
       "      <td>like new</td>\n",
       "      <td>None</td>\n",
       "      <td>gas</td>\n",
       "      <td>62161</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>baltimore</td>\n",
       "      <td>8345</td>\n",
       "      <td>2011</td>\n",
       "      <td>subaru</td>\n",
       "      <td>forester</td>\n",
       "      <td>None</td>\n",
       "      <td>4 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>127848</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>mid-size</td>\n",
       "      <td>wagon</td>\n",
       "      <td>None</td>\n",
       "      <td>md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kalispell</td>\n",
       "      <td>26999</td>\n",
       "      <td>2012</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>tahoe 1500 ltz 4x4 gas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>gas</td>\n",
       "      <td>109227</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>None</td>\n",
       "      <td>SUV</td>\n",
       "      <td>call 844-206-2069 and mention stock # 82777  ...</td>\n",
       "      <td>specializing in our signature lifted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>south coast</td>\n",
       "      <td>14988</td>\n",
       "      <td>2017</td>\n",
       "      <td>ford</td>\n",
       "      <td>fusion</td>\n",
       "      <td>excellent</td>\n",
       "      <td>4 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>60759</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>fwd</td>\n",
       "      <td>None</td>\n",
       "      <td>sedan</td>\n",
       "      <td>None</td>\n",
       "      <td>ma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>santa barbara</td>\n",
       "      <td>5975</td>\n",
       "      <td>2009</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>traverse</td>\n",
       "      <td>excellent</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>197000</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>fwd</td>\n",
       "      <td>mid-size</td>\n",
       "      <td>SUV</td>\n",
       "      <td>None</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>chicago</td>\n",
       "      <td>4990</td>\n",
       "      <td>2011</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>malibu ltz</td>\n",
       "      <td>good</td>\n",
       "      <td>4 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>171000</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>fwd</td>\n",
       "      <td>mid-size</td>\n",
       "      <td>sedan</td>\n",
       "      <td>None</td>\n",
       "      <td>il</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tucson</td>\n",
       "      <td>7499</td>\n",
       "      <td>2010</td>\n",
       "      <td>mazda</td>\n",
       "      <td>mazda6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>gas</td>\n",
       "      <td>149219</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sedan</td>\n",
       "      <td>None</td>\n",
       "      <td>az</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>eastern panhandle</td>\n",
       "      <td>5990</td>\n",
       "      <td>2000</td>\n",
       "      <td>ford</td>\n",
       "      <td>f150</td>\n",
       "      <td>excellent</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>166508</td>\n",
       "      <td>clean</td>\n",
       "      <td>manual</td>\n",
       "      <td>4wd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>truck</td>\n",
       "      <td>None</td>\n",
       "      <td>wv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                region  price  year manufacturer                   model  \\\n",
       "243        long island  13695  2007     cadillac                escalade   \n",
       "10            lakeland  40990  2017    chevrolet          silverado 1500   \n",
       "88               tulsa  28999  2018         ford                   f-150   \n",
       "279          baltimore   8345  2011       subaru                forester   \n",
       "8            kalispell  26999  2012    chevrolet  tahoe 1500 ltz 4x4 gas   \n",
       "223        south coast  14988  2017         ford                  fusion   \n",
       "252      santa barbara   5975  2009    chevrolet                traverse   \n",
       "103            chicago   4990  2011    chevrolet              malibu ltz   \n",
       "91              tucson   7499  2010        mazda                  mazda6   \n",
       "281  eastern panhandle   5990  2000         ford                    f150   \n",
       "\n",
       "     condition    cylinders fuel odometer title_status transmission drive  \\\n",
       "243       None         None  gas   144492        clean    automatic   4wd   \n",
       "10   excellent  8 cylinders  gas    47021        clean    automatic   4wd   \n",
       "88    like new         None  gas    62161        clean    automatic  None   \n",
       "279       None  4 cylinders  gas   127848        clean    automatic   4wd   \n",
       "8         None         None  gas   109227        clean    automatic   4wd   \n",
       "223  excellent  4 cylinders  gas    60759        clean    automatic   fwd   \n",
       "252  excellent  6 cylinders  gas   197000        clean    automatic   fwd   \n",
       "103       good  4 cylinders  gas   171000        clean    automatic   fwd   \n",
       "91        None         None  gas   149219        clean    automatic  None   \n",
       "281  excellent  6 cylinders  gas   166508        clean       manual   4wd   \n",
       "\n",
       "          size    type                                             county  \\\n",
       "243       None     SUV                                               None   \n",
       "10   full-size  pickup                                               None   \n",
       "88        None    None                                               None   \n",
       "279   mid-size   wagon                                               None   \n",
       "8         None     SUV   call 844-206-2069 and mention stock # 82777  ...   \n",
       "223       None   sedan                                               None   \n",
       "252   mid-size     SUV                                               None   \n",
       "103   mid-size   sedan                                               None   \n",
       "91        None   sedan                                               None   \n",
       "281  full-size   truck                                               None   \n",
       "\n",
       "                                     state  \n",
       "243                                     ny  \n",
       "10                                      fl  \n",
       "88                                      ok  \n",
       "279                                     md  \n",
       "8     specializing in our signature lifted  \n",
       "223                                     ma  \n",
       "252                                     ca  \n",
       "103                                     il  \n",
       "91                                      az  \n",
       "281                                     wv  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df.sample(n=10,replace=False,random_state=63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region          object\n",
       "price           object\n",
       "year            object\n",
       "manufacturer    object\n",
       "model           object\n",
       "condition       object\n",
       "cylinders       object\n",
       "fuel            object\n",
       "odometer        object\n",
       "title_status    object\n",
       "transmission    object\n",
       "drive           object\n",
       "size            object\n",
       "type            object\n",
       "county          object\n",
       "state           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/05 22:14:09 WARN TransportChannelHandler: Exception in connection from /192.168.43.222:44227\n",
      "java.io.IOException: Connection timed out\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "22/04/05 23:33:52 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 4500956 ms exceeds timeout 120000 ms\n",
      "22/04/05 23:33:53 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "ex_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
